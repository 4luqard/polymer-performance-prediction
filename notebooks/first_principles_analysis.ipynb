{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Principles Analysis of Polymer Properties\n",
    "\n",
    "This notebook analyzes how well first-principles chemistry predictions align with the competition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load training data - adjust path for Kaggle vs local\nimport os\nif os.path.exists('/kaggle/input'):\n    # Kaggle environment\n    train_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\nelse:\n    # Local environment\n    train_df = pd.read_csv('../data/raw/train.csv')\n\nprint(f\"Training data shape: {train_df.shape}\")\nprint(f\"\\nColumns: {train_df.columns.tolist()}\")\nprint(f\"\\nTarget statistics:\")\nfor col in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n    non_null = train_df[col].notna().sum()\n    print(f\"{col}: {non_null} non-null values ({non_null/len(train_df)*100:.1f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample SMILES\n",
    "print(\"Sample SMILES structures:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}: {train_df['SMILES'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First-Principles Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Van der Waals volumes (Å³)\n",
    "VDW_VOLUMES = {\n",
    "    'CH3': 33.5, 'CH2': 26.7, 'CH': 20.0, 'C': 13.2,\n",
    "    'c': 16.5,  # aromatic C\n",
    "    'O_ether': 11.5, 'O_carbonyl': 14.0,\n",
    "    'N': 12.0, 'F': 10.5, 'Cl': 26.0, 'Br': 32.0,\n",
    "    'S': 22.0\n",
    "}\n",
    "\n",
    "# Molar volumes at 298K (cm³/mol)\n",
    "MOLAR_VOLUMES = {\n",
    "    'CH3': 33.5, 'CH2': 16.1, 'CH': 13.5, 'C': 11.0,\n",
    "    'c': 13.7,  # aromatic C\n",
    "    'C=O': 22.0, 'O': 10.0, 'OH': 14.0,\n",
    "    'N': 12.0, 'F': 11.0, 'Cl': 24.0, 'Br': 31.0,\n",
    "    'S': 19.0\n",
    "}\n",
    "\n",
    "# Atomic weights\n",
    "ATOMIC_WEIGHTS = {\n",
    "    'C': 12.01, 'H': 1.008, 'O': 16.00, 'N': 14.01,\n",
    "    'F': 19.00, 'Cl': 35.45, 'Br': 79.90, 'S': 32.07\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_polymer_structure(smiles):\n",
    "    \"\"\"Extract structural features for first-principles calculations\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic counts\n",
    "    features['length'] = len(smiles)\n",
    "    features['num_C'] = len(re.findall(r'C(?![l])', smiles))  # C not followed by l\n",
    "    features['num_c_aromatic'] = len(re.findall(r'c', smiles))\n",
    "    features['num_O'] = len(re.findall(r'O', smiles))\n",
    "    features['num_N'] = len(re.findall(r'N', smiles))\n",
    "    features['num_F'] = smiles.count('F')\n",
    "    features['num_Cl'] = smiles.count('Cl')\n",
    "    features['num_Br'] = smiles.count('Br')\n",
    "    features['num_S'] = len(re.findall(r'S(?![\\(=])', smiles))  # S not in sulfone\n",
    "    \n",
    "    # Structural features\n",
    "    features['num_rings'] = sum(smiles.count(str(i)) for i in range(1, 10))\n",
    "    features['num_aromatic_rings'] = len(re.findall(r'c1ccccc1|c1ccc\\(.*?\\)cc1', smiles))\n",
    "    features['num_branches'] = smiles.count('(')\n",
    "    features['num_polymer_ends'] = smiles.count('*')\n",
    "    \n",
    "    # Functional groups\n",
    "    features['has_carbonyl'] = int('C(=O)' in smiles or 'C=O' in smiles)\n",
    "    features['has_ether'] = int(bool(re.search(r'COC|cOc', smiles)))\n",
    "    features['has_hydroxyl'] = int('OH' in smiles or 'O[H]' in smiles)\n",
    "    features['has_amine'] = int('N' in smiles)\n",
    "    features['has_sulfone'] = int('S(=O)(=O)' in smiles)\n",
    "    features['has_ester'] = int('C(=O)O' in smiles or 'COO' in smiles)\n",
    "    \n",
    "    # Chain flexibility indicators\n",
    "    features['num_single_bonds'] = smiles.count('-')\n",
    "    features['num_ether_linkages'] = len(re.findall(r'COC|cOc', smiles))\n",
    "    features['aromatic_fraction'] = features['num_c_aromatic'] / max(features['num_C'] + features['num_c_aromatic'], 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tg_first_principles(features):\n",
    "    \"\"\"Estimate Tg using first-principles rules\"\"\"\n",
    "    # Base temperature for aliphatic polymer\n",
    "    tg = -50  # °C\n",
    "    \n",
    "    # Aromatic rings increase Tg\n",
    "    tg += features['num_aromatic_rings'] * 30\n",
    "    \n",
    "    # Polar groups increase Tg\n",
    "    tg += features['has_carbonyl'] * 20\n",
    "    tg += features['has_hydroxyl'] * 25\n",
    "    tg += features['has_amine'] * 15\n",
    "    tg += features['has_sulfone'] * 30\n",
    "    \n",
    "    # Flexible ether linkages decrease Tg\n",
    "    tg -= features['num_ether_linkages'] * 10\n",
    "    \n",
    "    # Bulky side groups (approximated by branching)\n",
    "    tg += min(features['num_branches'], 5) * 5\n",
    "    \n",
    "    # Halogen effects\n",
    "    tg += features['num_F'] * 5\n",
    "    tg += features['num_Cl'] * 10\n",
    "    tg += features['num_Br'] * 12\n",
    "    \n",
    "    return tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_density_first_principles(features):\n",
    "    \"\"\"Estimate density using group contribution\"\"\"\n",
    "    # Simplified calculation based on composition\n",
    "    total_weight = 0\n",
    "    total_volume = 0\n",
    "    \n",
    "    # Carbon atoms\n",
    "    n_carbon = features['num_C'] + features['num_c_aromatic']\n",
    "    total_weight += n_carbon * ATOMIC_WEIGHTS['C']\n",
    "    total_volume += features['num_C'] * 16.1  # aliphatic CH2 average\n",
    "    total_volume += features['num_c_aromatic'] * 13.7  # aromatic\n",
    "    \n",
    "    # Heteroatoms\n",
    "    total_weight += features['num_O'] * ATOMIC_WEIGHTS['O']\n",
    "    total_volume += features['num_O'] * 10.0\n",
    "    \n",
    "    total_weight += features['num_N'] * ATOMIC_WEIGHTS['N']\n",
    "    total_volume += features['num_N'] * 12.0\n",
    "    \n",
    "    total_weight += features['num_F'] * ATOMIC_WEIGHTS['F']\n",
    "    total_volume += features['num_F'] * 11.0\n",
    "    \n",
    "    total_weight += features['num_Cl'] * ATOMIC_WEIGHTS['Cl']\n",
    "    total_volume += features['num_Cl'] * 24.0\n",
    "    \n",
    "    # Estimate H atoms (simplified)\n",
    "    n_hydrogen = 2 * n_carbon - features['num_rings'] * 2\n",
    "    total_weight += n_hydrogen * ATOMIC_WEIGHTS['H']\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if total_volume == 0:\n",
    "        return 1.0  # default\n",
    "    \n",
    "    # Convert to g/cm³\n",
    "    density = total_weight / total_volume\n",
    "    \n",
    "    # Typical polymer range\n",
    "    return np.clip(density, 0.8, 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ffv_first_principles(features, density):\n",
    "    \"\"\"Estimate FFV using Bondi's method\"\"\"\n",
    "    # Calculate van der Waals volume (simplified)\n",
    "    vdw_volume = 0\n",
    "    \n",
    "    # Carbon contributions\n",
    "    vdw_volume += features['num_C'] * 26.7  # CH2 average\n",
    "    vdw_volume += features['num_c_aromatic'] * 16.5\n",
    "    \n",
    "    # Heteroatom contributions\n",
    "    vdw_volume += features['num_O'] * 11.5\n",
    "    vdw_volume += features['num_N'] * 12.0\n",
    "    vdw_volume += features['num_F'] * 10.5\n",
    "    vdw_volume += features['num_Cl'] * 26.0\n",
    "    \n",
    "    # Calculate molecular weight (simplified)\n",
    "    mol_weight = (features['num_C'] + features['num_c_aromatic']) * 14  # CH2 average\n",
    "    mol_weight += features['num_O'] * 16\n",
    "    mol_weight += features['num_N'] * 14\n",
    "    mol_weight += features['num_F'] * 19\n",
    "    mol_weight += features['num_Cl'] * 35.5\n",
    "    \n",
    "    if mol_weight == 0:\n",
    "        return 0.15  # default\n",
    "    \n",
    "    # Bondi's equation: FFV = (V - 1.3*Vw)/V\n",
    "    specific_volume = 1 / density\n",
    "    occupied_volume = 1.3 * vdw_volume / mol_weight\n",
    "    \n",
    "    ffv = (specific_volume - occupied_volume) / specific_volume\n",
    "    \n",
    "    # Typical range\n",
    "    return np.clip(ffv, 0.05, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rg_first_principles(features):\n",
    "    \"\"\"Estimate radius of gyration\"\"\"\n",
    "    # Estimate backbone length\n",
    "    backbone_bonds = features['num_C'] + features['num_c_aromatic']\n",
    "    \n",
    "    # Persistence length estimation\n",
    "    base_lp = 0.7  # nm\n",
    "    lp = base_lp\n",
    "    lp += features['num_aromatic_rings'] * 0.5  # rigidity from aromatic rings\n",
    "    lp -= features['num_ether_linkages'] * 0.2  # flexibility from ethers\n",
    "    \n",
    "    # Use simplified Kuhn model\n",
    "    # Rg = sqrt(N*b²/6) where N is number of segments, b is segment length\n",
    "    segment_length = lp * 2  # Kuhn length approximation\n",
    "    n_segments = backbone_bonds / 5  # approximate Kuhn segments\n",
    "    \n",
    "    rg = np.sqrt(n_segments * segment_length**2 / 6) * 10  # convert to Å\n",
    "    \n",
    "    # Typical range\n",
    "    return np.clip(rg, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tc_first_principles(features, tg):\n",
    "    \"\"\"Estimate crystallization temperature\"\"\"\n",
    "    # Assess crystallinity tendency\n",
    "    crystallinity_score = 0\n",
    "    \n",
    "    # Regular structure promotes crystallization\n",
    "    if features['aromatic_fraction'] > 0.5:\n",
    "        crystallinity_score += 0.3\n",
    "    \n",
    "    # Linear chains promote crystallization\n",
    "    if features['num_branches'] < 2:\n",
    "        crystallinity_score += 0.3\n",
    "    \n",
    "    # Too many different groups inhibit crystallization\n",
    "    n_different_groups = sum([\n",
    "        features['has_carbonyl'], features['has_ether'],\n",
    "        features['has_hydroxyl'], features['has_amine']\n",
    "    ])\n",
    "    crystallinity_score -= n_different_groups * 0.1\n",
    "    \n",
    "    crystallinity_score = np.clip(crystallinity_score, 0, 1)\n",
    "    \n",
    "    if crystallinity_score > 0.3:\n",
    "        # Empirical: Tc ≈ 0.85 * Tm, Tm ≈ Tg + 100\n",
    "        tm = tg + 100\n",
    "        tc = 0.85 * tm\n",
    "        # Convert to competition scale (seems to be normalized)\n",
    "        return tc / 1000  # rough normalization\n",
    "    else:\n",
    "        return 0.0  # amorphous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply First-Principles Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and calculate first-principles predictions\n",
    "print(\"Calculating first-principles predictions...\")\n",
    "\n",
    "fp_features = []\n",
    "fp_predictions = {\n",
    "    'Tg_fp': [], 'Density_fp': [], 'FFV_fp': [],\n",
    "    'Rg_fp': [], 'Tc_fp': []\n",
    "}\n",
    "\n",
    "for smiles in train_df['SMILES']:\n",
    "    features = analyze_polymer_structure(smiles)\n",
    "    fp_features.append(features)\n",
    "    \n",
    "    # Calculate properties\n",
    "    tg = estimate_tg_first_principles(features)\n",
    "    density = estimate_density_first_principles(features)\n",
    "    ffv = estimate_ffv_first_principles(features, density)\n",
    "    rg = estimate_rg_first_principles(features)\n",
    "    tc = estimate_tc_first_principles(features, tg)\n",
    "    \n",
    "    fp_predictions['Tg_fp'].append(tg)\n",
    "    fp_predictions['Density_fp'].append(density)\n",
    "    fp_predictions['FFV_fp'].append(ffv)\n",
    "    fp_predictions['Rg_fp'].append(rg)\n",
    "    fp_predictions['Tc_fp'].append(tc)\n",
    "\n",
    "# Add to dataframe\n",
    "for key, values in fp_predictions.items():\n",
    "    train_df[key] = values\n",
    "\n",
    "print(\"First-principles calculations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare First-Principles vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Competition metric - inline definition for Kaggle compatibility\nMINMAX_DICT = {\n    'Tg': [-148.0297376, 472.25],\n    'FFV': [0.2269924, 0.77709707],\n    'Tc': [0.0465, 0.524],\n    'Density': [0.748691234, 1.840998909],\n    'Rg': [9.7283551, 34.672905605],\n}\n\ndef scaling_error(labels, preds, property):\n    \"\"\"Calculate scaled error for a property\"\"\"\n    error = np.abs(labels - preds)\n    min_val, max_val = MINMAX_DICT[property]\n    label_range = max_val - min_val\n    return np.mean(error / label_range)\n\ndef get_property_weights(labels):\n    \"\"\"Calculate property weights based on inverse square root of valid samples\"\"\"\n    property_weight = []\n    for property in MINMAX_DICT.keys():\n        if isinstance(labels, pd.DataFrame):\n            valid_num = np.sum(labels[property].notna())\n        else:\n            valid_num = np.sum(labels[property].notna()) if property in labels else 0\n        property_weight.append(valid_num)\n    property_weight = np.array(property_weight)\n    property_weight = np.sqrt(1 / np.maximum(property_weight, 1))\n    return (property_weight / np.sum(property_weight)) * len(property_weight)\n\ndef neurips_polymer_metric(y_true, y_pred, target_names=None):\n    \"\"\"\n    NeurIPS Open Polymer Prediction 2025 competition metric.\n    \n    Implements weighted Mean Absolute Error (wMAE) with:\n    - Scaling by property range\n    - Weighting by inverse square root of valid samples\n    \"\"\"\n    if target_names is None:\n        target_names = list(MINMAX_DICT.keys())\n    \n    # Convert to DataFrames if needed\n    if isinstance(y_true, np.ndarray):\n        y_true = pd.DataFrame(y_true, columns=target_names)\n    if isinstance(y_pred, np.ndarray):\n        y_pred = pd.DataFrame(y_pred, columns=target_names)\n    \n    property_maes = []\n    property_weights = get_property_weights(y_true)\n    individual_scores = {}\n    \n    for i, property in enumerate(target_names):\n        # Handle missing values - only evaluate where we have true labels\n        is_labeled = y_true[property].notna()\n        \n        if is_labeled.sum() > 0:\n            mae = scaling_error(\n                y_true.loc[is_labeled, property].values,\n                y_pred.loc[is_labeled, property].values,\n                property\n            )\n            property_maes.append(mae)\n            individual_scores[property] = mae\n        else:\n            individual_scores[property] = np.nan\n    \n    if len(property_maes) == 0:\n        return np.nan, individual_scores\n    \n    # Calculate weighted average\n    final_score = float(np.average(property_maes, weights=property_weights[:len(property_maes)]))\n    \n    return final_score, individual_scores\n\n# Create comparison plots\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.flatten()\n\nproperties = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\nunits = ['°C', '', '', 'g/cm³', 'Å']\n\nfor i, (prop, unit) in enumerate(zip(properties, units)):\n    # Get non-null actual values\n    mask = train_df[prop].notna()\n    actual = train_df[mask][prop]\n    predicted = train_df[mask][f'{prop}_fp']\n    \n    if len(actual) > 0:\n        # Scatter plot\n        axes[i].scatter(actual, predicted, alpha=0.5)\n        \n        # Perfect prediction line\n        min_val = min(actual.min(), predicted.min())\n        max_val = max(actual.max(), predicted.max())\n        axes[i].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n        \n        # Calculate competition metric for this property\n        prop_df_true = pd.DataFrame({prop: actual})\n        prop_df_pred = pd.DataFrame({prop: predicted})\n        score, _ = neurips_polymer_metric(prop_df_true, prop_df_pred, [prop])\n        \n        # Also calculate R² for reference\n        if len(actual) > 1:\n            correlation = np.corrcoef(actual, predicted)[0, 1]\n            axes[i].text(0.05, 0.95, f'Competition Score: {score:.4f}\\\\nR² = {correlation**2:.3f}',\n                        transform=axes[i].transAxes, verticalalignment='top',\n                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n        \n        axes[i].set_xlabel(f'Actual {prop} {unit}')\n        axes[i].set_ylabel(f'First-Principles {prop} {unit}')\n        axes[i].set_title(f'{prop} Comparison (n={len(actual)})')\n    else:\n        axes[i].text(0.5, 0.5, f'No data for {prop}',\n                    transform=axes[i].transAxes,\n                    ha='center', va='center')\n\n# Remove empty subplot\nfig.delaxes(axes[5])\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (prop, unit) in enumerate(zip(properties, units)):\n",
    "    # Get non-null actual values\n",
    "    mask = train_df[prop].notna()\n",
    "    \n",
    "    if mask.sum() > 0:\n",
    "        actual = train_df[mask][prop]\n",
    "        predicted_all = train_df[f'{prop}_fp']\n",
    "        \n",
    "        # Plot distributions\n",
    "        axes[i].hist(actual, bins=30, alpha=0.5, label='Actual', density=True)\n",
    "        axes[i].hist(predicted_all, bins=30, alpha=0.5, label='First-Principles (all)', density=True)\n",
    "        \n",
    "        axes[i].set_xlabel(f'{prop} {unit}')\n",
    "        axes[i].set_ylabel('Density')\n",
    "        axes[i].set_title(f'{prop} Distribution')\n",
    "        axes[i].legend()\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, f'No data for {prop}',\n",
    "                    transform=axes[i].transAxes,\n",
    "                    ha='center', va='center')\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance for First-Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which structural features correlate with properties\n",
    "feature_names = list(fp_features[0].keys())\n",
    "feature_matrix = pd.DataFrame(fp_features)\n",
    "\n",
    "# Calculate correlations with actual values\n",
    "correlations = {}\n",
    "for prop in properties:\n",
    "    mask = train_df[prop].notna()\n",
    "    if mask.sum() > 10:  # Need enough data\n",
    "        corr_values = []\n",
    "        for feat in feature_names:\n",
    "            if feature_matrix[feat].std() > 0:  # Avoid constant features\n",
    "                corr = np.corrcoef(feature_matrix[mask][feat], train_df[mask][prop])[0, 1]\n",
    "                corr_values.append(abs(corr))\n",
    "            else:\n",
    "                corr_values.append(0)\n",
    "        correlations[prop] = corr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance heatmap\n",
    "if correlations:\n",
    "    corr_df = pd.DataFrame(correlations, index=feature_names)\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.heatmap(corr_df, cmap='YlOrRd', cbar_kws={'label': 'Absolute Correlation'})\n",
    "    plt.title('Structural Feature Correlations with Properties')\n",
    "    plt.xlabel('Property')\n",
    "    plt.ylabel('Structural Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics using competition metric\nprint(\"Summary of First-Principles vs Actual (Competition Metric - wMAE):\")\nprint(\"=\"*60)\n\n# Create comparison dataframes for overall metric calculation\ncomparison_data = {}\nfor prop in properties:\n    mask = train_df[prop].notna()\n    if mask.sum() > 0:\n        comparison_data[prop] = train_df[mask][prop]\n        comparison_data[f'{prop}_fp'] = train_df[mask][f'{prop}_fp']\n\n# Calculate overall competition metric using the actual vs predicted values\nactual_df = pd.DataFrame({prop: comparison_data[prop] for prop in properties if prop in comparison_data})\npredicted_df = pd.DataFrame({prop: comparison_data[f'{prop}_fp'] for prop in properties if prop in comparison_data})\n\nif len(actual_df.columns) > 0:\n    overall_score, individual_scores = neurips_polymer_metric(actual_df, predicted_df)\n    \n    print(f\"\\nOverall Competition Metric (wMAE): {overall_score:.4f}\")\n    print(\"\\nIndividual Property Scores (scaled MAE):\")\n    for prop, score in individual_scores.items():\n        if not np.isnan(score):\n            print(f\"  {prop}: {score:.4f} ({score*100:.2f}% of range)\")\n        else:\n            print(f\"  {prop}: No data\")\n\n# Also show correlations for context\nprint(\"\\n\\nCorrelations (for reference):\")\nfor prop in properties:\n    mask = train_df[prop].notna()\n    if mask.sum() > 1:\n        actual = train_df[mask][prop]\n        predicted = train_df[mask][f'{prop}_fp']\n        \n        corr = actual.corr(predicted)\n        mae = (actual - predicted).abs().mean()\n        rmse = np.sqrt(((actual - predicted) ** 2).mean())\n        print(f\"\\n{prop}:\")\n        print(f\"  Correlation: {corr:.3f}\")\n        print(f\"  MAE: {mae:.3f}\")\n        print(f\"  RMSE: {rmse:.3f}\")\n        print(f\"  N samples: {mask.sum()}\")\n    else:\n        print(f\"\\n{prop}: Insufficient data\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Insights and Recommendations\n",
    "\n",
    "Based on the first-principles analysis:\n",
    "\n",
    "1. **Correlation Quality**: Document how well first-principles predictions correlate with actual values\n",
    "2. **Feature Engineering**: The structural features used in first-principles can be valuable for ML\n",
    "3. **Physical Constraints**: First-principles provides reasonable bounds for predictions\n",
    "4. **Hybrid Approach**: Consider using first-principles predictions as additional features in ML model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}